{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "743b3f3f-56bb-4889-a0a2-f09d906feef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bronze Layer: Cargo Manifest with COPY INTO\n",
    "**Ingestion Pattern**: COPY INTO\n",
    "\n",
    "**Features**:\n",
    " - Idempotent loads (same file won't be loaded twice)\n",
    " - Efficient for batch loads\n",
    " - Automatic schema inference\n",
    " - File-level tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58046e09-4909-4109-8257-6fab05d077b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from datetime import date\n",
    "import logging\n",
    "\n",
    "# Import utilities\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from logging_utils import get_logger\n",
    "from validation_utils import validate_manifest_data\n",
    "\n",
    "logger = get_logger(\"bronze_manifest_copyinto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14dd00cc-e654-46b0-842a-5e3a44181e06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get parameters\n",
    "dbutils.widgets.text(\"catalog_name\", \"cargo_fleet_dev\", \"Catalog\")\n",
    "dbutils.widgets.text(\"load_date\", str(date.today()), \"Load Date\")\n",
    "\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
    "load_date = dbutils.widgets.get(\"load_date\")\n",
    "\n",
    "bronze_table = f\"{catalog_name}.bronze.cargo_manifest_raw\"\n",
    "source_path = f\"/Volumes/{catalog_name}/bronze/manifest_landing\"\n",
    "\n",
    "logger.info(f\"Starting COPY INTO for load date: {load_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f29386-efc2-4b97-b448-480a98984842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {bronze_table} (\n",
    "            manifest_id STRING,\n",
    "            ship_id STRING,\n",
    "            voyage_number STRING,\n",
    "            load_port STRING,\n",
    "            destination_port STRING,\n",
    "            departure_date DATE,\n",
    "            estimated_arrival_date DATE,\n",
    "            container_id STRING,\n",
    "            cargo_type STRING,\n",
    "            cargo_weight_kg DOUBLE,\n",
    "            cargo_value_usd DOUBLE,\n",
    "            shipper_name STRING,\n",
    "            consignee_name STRING,\n",
    "            special_handling STRING,\n",
    "            load_timestamp TIMESTAMP,\n",
    "            ingestion_timestamp TIMESTAMP,\n",
    "            source_file STRING\n",
    "        )\n",
    "        USING DELTA\n",
    "        PARTITIONED BY (departure_date)\n",
    "        COMMENT 'Raw cargo manifest data from daily batch loads'\n",
    "    \"\"\")\n",
    "    \n",
    "    logger.info(f\"✓ Target table created/verified: {bronze_table}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create target table: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2144de3c-5b06-4b1a-a09b-5fd649bdc834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_pattern = f\"{source_path}/manifest_{load_date.replace('-', '')}.parquet\"\n",
    "\n",
    "try:\n",
    "    # Execute COPY INTO command\n",
    "    result = spark.sql(f\"\"\"\n",
    "        COPY INTO {bronze_table}\n",
    "        FROM (\n",
    "            SELECT \n",
    "                *,\n",
    "                current_timestamp() as ingestion_timestamp,\n",
    "                _metadata.file_path as source_file\n",
    "            FROM '{file_pattern}'\n",
    "        )\n",
    "        FILEFORMAT = PARQUET\n",
    "        FORMAT_OPTIONS ('mergeSchema' = 'true')\n",
    "        COPY_OPTIONS ('mergeSchema' = 'true')\n",
    "    \"\"\")\n",
    "    \n",
    "    # Get load statistics\n",
    "    stats = result.collect()[0]\n",
    "    num_rows_loaded = stats['num_affected_rows']\n",
    "    \n",
    "    logger.info(f\"✓ COPY INTO completed successfully\")\n",
    "    logger.info(f\"  - Rows loaded: {num_rows_loaded}\")\n",
    "    logger.info(f\"  - Target table: {bronze_table}\")\n",
    "    \n",
    "    # Display result\n",
    "    display(result)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"COPY INTO failed: {str(e)}\")\n",
    "    \n",
    "    # Check if file already loaded (idempotent behavior)\n",
    "    if \"already loaded\" in str(e).lower():\n",
    "        logger.warning(f\"File already loaded (idempotent): {file_pattern}\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7fe5296-9712-452b-9319-0795a4f3d9a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count records loaded today\n",
    "df_today = spark.sql(f\"\"\"\n",
    "    SELECT COUNT(*) as record_count,\n",
    "           COUNT(DISTINCT manifest_id) as manifest_count,\n",
    "           COUNT(DISTINCT ship_id) as ship_count\n",
    "    FROM {bronze_table}\n",
    "    WHERE DATE(ingestion_timestamp) = CURRENT_DATE()\n",
    "\"\"\")\n",
    "\n",
    "display(df_today)\n",
    "\n",
    "# Show sample records\n",
    "df_sample = spark.table(bronze_table).filter(\n",
    "    col(\"ingestion_timestamp\") >= current_date()\n",
    ").limit(10)\n",
    "\n",
    "display(df_sample)\n",
    "\n",
    "logger.info(\"Load verification completed\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest_manifest_copyinto.py",
   "widgets": {
    "catalog_name": {
     "currentValue": "cargo_fleet_dev",
     "nuid": "4daf6b17-f3f4-49ea-a03d-5bd5b6ac1bf6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "cargo_fleet_dev",
      "label": "Catalog",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "cargo_fleet_dev",
      "label": "Catalog",
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "load_date": {
     "currentValue": "2025-12-20",
     "nuid": "0054da1d-091e-4614-ad23-bbe69188a08c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-12-20",
      "label": "Load Date",
      "name": "load_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-12-20",
      "label": "Load Date",
      "name": "load_date",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
